(window.webpackJsonp=window.webpackJsonp||[]).push([[181],{523:function(t,s,a){"use strict";a.r(s);var n=a(13),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("Scrapy是一个用于爬网网站并提取结构化数据的应用程序框架，可用于各种有用的应用程序，例如数据挖掘，信息处理或历史档案。")]),t._v(" "),a("p",[t._v("即使Scrapy最初是为Web抓取而设计的，它也可以用于使用API（例如Amazon Associates Web Services）或用作通用Web搜寻器来提取数据")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# quotes_spider.py")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scrapy\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("QuoteSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'quote'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# url")]),t._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://quotes.toscrape.com/tag/humor/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        quotes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"quote\"]'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" quote "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" quotes"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'author'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" quote"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'span/small/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'title'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" quote"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'span[@class=\"text\"]/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分页中下一页")]),t._v("\n        next_page "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//li[@class=\"next\"]/a0h0ref'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" next_page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("follow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("next_page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])])]),a("p",[t._v("运行代码")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建项目")]),t._v("\nscrapy startproject PROJECT_NAME\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生成spider文件按")]),t._v("\nscrapy genspider  SPIDER_NAME DOMAIN_NAME "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# -指定模板")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 运行爬虫")]),t._v("\nscrapy crawl SPINDER_NAME -o quotes.json\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 单独运行爬虫文件")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 运行并保存内容为json格式,只需要py文件即可运行")]),t._v("\nscrapy runspider SPIDER_NAME.py -o quotes.json\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 保存为csv格式")]),t._v("\nscrapy runspider SPIDER_NAME.py -o quotes.csv -t csv\n")])])]),a("p",[t._v("scrapy shell")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Scrapy终端是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath或CSS表达式，查看他们的工作方式，方便我们爬取的网页中提取的数据,如果安装ipython会使用ipython的终端")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# scrapy shell [url]")]),t._v("\nscrapy startproject baidu\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\nYou can start your first spider with:\n    cd baidu\n    scrapy genspider example example.com\n'''")]),t._v("\ncd baidu \nscrapy genspider test www"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("baidu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com\n"),a("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\nCreated spider 'test' using template 'basic' in module:\n  baidu.spiders.test\n'''")]),t._v("\nscrapy shell http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("//")]),t._v("www"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("baidu"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("com\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# scrapy view [url] 用项目配置下载网页， 然后用浏览器打开")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# scrapy fetch [url] 用项目配置下载网页， 然后输出至控制台")]),t._v("\n")])])]),a("p",[t._v("scrapy shell内置函数")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("函数")]),t._v(" "),a("th",[t._v("说明")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("fetch")]),t._v(" "),a("td",[t._v("请求url或者Request对象， 注意， 请求成功之后会自动将当前域内的request和response对象重新赋值")])]),t._v(" "),a("tr",[a("td",[t._v("view")]),t._v(" "),a("td",[t._v("用浏览器打开response对象内的网页")])]),t._v(" "),a("tr",[a("td",[t._v("shelp()")]),t._v(" "),a("td",[t._v("打印出帮助信息")])]),t._v(" "),a("tr",[a("td",[t._v("spider")]),t._v(" "),a("td",[t._v("相应的Spider对象的实例（default|SPIDER）")])]),t._v(" "),a("tr",[a("td",[t._v("setting")]),t._v(" "),a("td",[t._v("保存所有配置信息的对象")])]),t._v(" "),a("tr",[a("td",[t._v("crawler")]),t._v(" "),a("td",[t._v("所有内置函数的集合 （crawler.setting is setting ）True")])]),t._v(" "),a("tr",[a("td"),t._v(" "),a("td")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);